\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Series and Product Developments}

A useful tool to explicitly represent an analytic function.

\section{Power Series}
\subsection{Weierstrass' Theorem}

In analysis, uniform convergence is crucial for studying the regularity properties of a limit function.

\paragraph{The Domain}
We now have a sequence of analytic functions $\left\{ f_n \right\}$ defined on $\Omega_n$. As we want to consider the limit function $f$ in $\Omega$, it would make sense that
\begin{equation*}
	\forall z\in \Omega, \exists n_0\in \mathbb{N}, \forall n>n_0, z\in \Omega_n.
\end{equation*}
A typical case is that $\Omega_n \subsetneq \Omega_{n+1}$ for all $n\in \mathbb{Z}_+$ and $\Omega = \bigcup_{n=1}^{\infty} \Omega_n$. In this way, however, the convergence is not uniform as no $f_n$ is defined on $\Omega$. So we consider a weaker assumption, but still strong enough: The inner compact uniform convergence.

\begin{theorem}{The Uniform Convergence Implies Analyticality}{The Uniform Convergence Implies Analyticality}
	Let $\left\{ f_n \right\}$ be a sequence of analytic functions defined on regions $\Omega_n$ with limit function $f(z) = \lim_{n \to \infty } f_n(z)$ defined on $\Omega$. If for every compact set $K \subset \Omega$, $f_n$ is uniformly convergent on $K$, then $f$ is analytic on $\Omega$.

	Moreover, $f_n'(z)$ converges uniformly to $f'(z)$ on every compact $K \subseteq \Omega$.
\end{theorem}
\begin{proof}
	Let $\Delta: \left|z-a\right|\leq r$ be a closed disk in $\Omega$, then for enough large $n$, we have $\Delta \subseteq \Omega_n$ (All $ \Omega_n $ forms an open cover of $ \Delta $, thus has a finite subcover). For any closed curve $\gamma$ in $\Delta$, we have
	\begin{equation*}
		\int_{\gamma} f(z) \mathrm{d} z = \lim_{n \to \infty} \int_{\gamma} f_n(z) \mathrm{d} z = 0.
	\end{equation*}
	due to uniform convergence. Thus, by Morera's theorem, $f$ is analytic on $\Delta$. Since $\Delta$ is arbitrary, we conclude that $f$ is analytic on $\Omega$.

	Explicitly, we can write
	\begin{equation*}
		f_n(z) = \frac{1}{2 \pi i}\int_C \frac{f_n(\zeta)}{\zeta - z} \mathrm{d} \zeta,
	\end{equation*}
	where $C: \left|\zeta-a\right|=r$ and $\left|z-a\right|<r$. Due to uniform convergence, we can exchange the limit and the integral:
	\begin{equation*}
		f(z) = \lim_{n \to \infty} f_n(z) = \frac{1}{2 \pi i}\int_C \lim_{n \to \infty} \frac{f_n(\zeta)}{\zeta - z} \mathrm{d} \zeta = \frac{1}{2 \pi i}\int_C \frac{f(\zeta)}{\zeta - z} \mathrm{d} \zeta.
	\end{equation*}
	showing $f$ is analytic in the disk.
Following the same route, we have
\begin{equation*}
	 f_n'(z) = \frac{1}{2 \pi i}\int_C \frac{f_n(\zeta)}{(\zeta - z)^2} \mathrm{d} \zeta,
\end{equation*}
So we have
\begin{equation}
 	\lim_{n \to \infty } f_n'(z) = \frac{1}{2 \pi i}\int_C \frac{f(\zeta)}{(\zeta - z)^2} \mathrm{d} \zeta = f'(z).
\end{equation}
In a compact set, convergence is uniform, thus we have finished the proof.
\end{proof}

Repeated applications suggest that $f_n^{(k)}(z)$ converges uniformly to $f^{(k)}(z)$ on every compact set $K \subseteq \Omega$.

Apply this to series, we naturally have the following theorem.
\begin{theorem}{Weierstrass Theorem}{Weierstrass Theorem}
	Let $\left\{ f_n \right\}$ be a sequence of analytic functions with limit function $f(z) = \sum_{n=1}^{\infty } f_n(z)$ defined on $\Omega$. If for every compact set $K \subseteq \Omega$, $\sum f_n$ is uniformly convergent on $K$, then $f$ is analytic on $\Omega$.

	Moreover, $\sum f_n'(z)$ converges uniformly to $f'(z)$ on every compact $K \subseteq \Omega$.
\end{theorem}

\begin{proposition}{Uniform Convergence on Compact Sets}{Uniform Convergence on Compact Sets}
	As $K$ is compact so is closed, then the maximum and minimum of $\left|f_n(z)-f_m(z)\right|$ is achieved on $\partial K$. So uniform convergence on $K$ is equivalent to uniform convergence on $\partial K$.
\end{proposition}

\begin{theorem}{Hurwitz Theorem}{Hurwitz Theorem}
	Let $\left\{ f_n \right\}$ be a sequence of analytic functions defined on $\Omega$, $f_n(z)\neq 0$, with limit function $f(z) = \lim_{n \to \infty } f_n(z)$ defined on $\Omega$. If for every compact set $K \subset \Omega$, $\left\{ f_n \right\}$ converges uniformly to $f$, then $f=0$ or $\forall z\in \Omega, f(z)\neq 0$.
\end{theorem}
\begin{proof}
Suppose $f$ is not identically zero, then the zeros are isolated. $\forall z_0\in \Omega$, let $r>0$ that $\forall 0<\left|z-z_0\right|\leq r, f(z) \neq 0$. Denote
\begin{equation*}
	C = \min \left\{ f(z): \left|z-z_0\right|=r \right\} >0
\end{equation*}
then $1 / f_n$ converges uniformly to $1 / f$ on $\left|z-z_0\right|=r$. Thus, there exists $n_0$ such that for all $n>n_0$, we have
\begin{equation*}
	\lim_{n \to \infty } \frac{1}{2 \pi i} \int_{C} \frac{f_n'(z)}{f_n'(z)} \mathrm{d} z = \frac{1}{2 \pi i} \int_{C} \frac{f'(z)}{f(z)} \mathrm{d} z = 0.
\end{equation*}

From theorem \ref{thm:Number of Zeros}, we know that the integral counts the number of zeros of $f_n$ in $\left|z-z_0\right|<r$, which is zero. So $f(z_0)\neq 0$. 
\end{proof}

\subsection{The Taylor Series}

According to theorem \ref{thm:Taylors Theorem}, let $f$ be analytic in the region $\Omega$. For ant $z,z_0\in \Omega$ we have
\begin{equation*}
	f(z) = \sum_{k=0}^n \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k + f_{n+1}(z)(z-z_0)^{n+1}.
\end{equation*}

Let $D \subseteq \Omega$ be a disk containing $z$ with center at $z_0$ and radius $\rho$. Then we have
\begin{equation*}
	f_{n+1}(z) = \int_{\partial D} \frac{f(\zeta)\mathrm{d} \zeta}{(\zeta-z_0)^{n+1}(\zeta-z)}.
\end{equation*}
Denote  $M = \max \left\{ \left|f(z)\right|: z\in \partial D \right\}$, then obtain
\begin{equation}
	\left|f_{n+1}(z)(z-z_0)^{n+1}\right| \leq \frac{M \left|z-z_0\right|^{n+1}}{\rho^n(\rho-\left|z-z_0\right|)}.
\end{equation}
which means that the remainder term inner compact uniform converges to zero in $D$ as $n\to \infty$.

\begin{theorem}{Taylor's Series}{Taylors Series}
	Let $f$ be analytic in the region $\Omega$. For any $z_0\in \Omega$ and any open disk $D \subseteq \Omega$ centered at $z_0$, the Taylor series
	\begin{equation*}
		S(z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D
	\end{equation*}
	converges uniformly to $f(z)$ on every compact subset of $D$.
\end{theorem}
Therefore, the radius of convergence is at least the distance from $z_0$ to the boundary of $\Omega$. (Well, it can be larger)

\begin{remark}
	The uniqueness of Taylor series is guaranteed by taking the derivative of the series term by term and evaluating at $z_0$.
\end{remark}

\begin{proposition}{The Derivatives and Integral of Taylor Series}{The Derivatives and Integral of Taylor Series}
	Let $f$ be analytic in the region $\Omega$ and $z_0\in \Omega$. The Taylor series of $f$ at $z_0$ is
	\begin{equation*}
		S(z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D
	\end{equation*}
	if $D$ is an open disk centered at $z_0$ contained in $\Omega$. Then $f(z)=S(z)$ for $z\in D$ and $S(z)$ converges uniformly to $f(z)$ on every compact subset of $D$.

	Independently speaking, $S$ is a power series, which is inner compact uniform convergent and analytic in an open disk $D$ of radius $R$ centered at $z_0$, and diverges for $\left|z-z_0\right|>R$. Moreover,
	\begin{itemize}
		\item The derivative of the series is
			\begin{equation*}
				S'(z) = \sum_{k=1}^{\infty} \frac{f^{(k)}(z_0)}{(k-1)!} (z-z_0)^{k-1}, \qquad z\in D.
			\end{equation*}
		\item The integral of the series is
			\begin{equation*}
				\int_{z_0}^{z} S(\zeta) \mathrm{d} \zeta = \sum_{k=0}^{\infty} \frac{f^{(k)}(z_0)}{(k+1)!} (z-z_0)^{k+1}, \qquad z\in D.
			\end{equation*}
	\end{itemize}
	which have the same radius of convergence $R$ as $S$.
\end{proposition}
\begin{proof}
	This is the Abel Disk Theorem \ref{thm:Abel Disk Theorem}.
\end{proof}

\begin{example}{Taylor Series of Elementary Functions}{Taylor Series of Elementary Functions}
	\begin{itemize}
	\item Exponential Function
		\begin{equation*}
			e^z = 1 + \frac{z}{1!} + \frac{z^2}{2!} + \cdots + \frac{z^n}{n!} + \cdots, \qquad z\in \mathbb{C}
		\end{equation*}
		This is of course the definition of $e^z$, but it is also the Taylor series at $z_0=0$ because of the uniqueness of Taylor series.
	\item Sine and Cosine Function
	\begin{equation*}
		\sin z = z - \frac{z^3}{3!} + \frac{z^5}{5!} - \cdots + (-1)^n \frac{z^{2n+1}}{(2n+1)!} + \cdots, \qquad z\in \mathbb{C}
	\end{equation*}
	\begin{equation*}
		\cos z = 1 - \frac{z^2}{2!} + \frac{z^4}{4!} - \cdots + (-1)^n \frac{z^{2n}}{(2n)!} + \cdots, \qquad z\in \mathbb{C}
	\end{equation*}
	\item Power and logarithm: For a non-$\mathbb{Z}_+$ power or logarithm, we need first to choose an analytic branch near the origin. For $(1+z)^{\mu}$ or $\log (1+z)$, we can choose the principal branch with a cut along $(-\infty ,-1]$. Then the Taylor series at $z_0=0$ is
	\begin{equation*}
		(1+z)^{\mu} = 1 + \mu z + \binom{\mu}{2} z^2 + \cdots + \binom{\mu}{n} z^n + \cdots, \qquad z\in \mathbb{C}, \left|z\right|<1
	\end{equation*}
	\begin{equation*}
		\log (1+z) = z - \frac{z^2}{2} + \frac{z^3}{3} - \cdots + (-1)^{n-1} \frac{z^n}{n} + \cdots, \qquad z\in \mathbb{C}, \left|z\right|<1
	\end{equation*}
	The radius of convergence is $1$ for both series if $\mu\notin \mathbb{Z}_+$, for if $R>1$, then all the derivative would be bounded for $\left|z\right|< 1$, which is not the case. For $\mu\in \mathbb{Z}_+$, then the series converges in $\mathbb{R}$.

	\item Arctangent and Arcsine: We determine the branch by
		\begin{equation*}
			\arctan z = \int_0^z \frac{1}{1+\zeta^2} \mathrm{d} \zeta, \qquad \arcsin z = \int_0^z \frac{1}{\sqrt{1-\zeta^2}} \mathrm{d} \zeta, \qquad z\in \mathbb{C}, \left|z\right|<1.
		\end{equation*}
		The path is taken to be any path from $0$ to $z$ that lies in the unit open disk. Through term-by-term integration, we have
		\begin{equation*}
			\arctan z = z - \frac{z^3}{3} + \frac{z^5}{5} - \cdots + (-1)^{n-1} \frac{z^{2n-1}}{2n-1} + \cdots, \qquad z\in \mathbb{C}, \left|z\right|<1
		\end{equation*}
		\begin{equation*}
			\arcsin z = z + \frac{z^3}{6} + \frac{3z^5}{40} + \cdots + \frac{(2n-1)!!}{(2n)!!} \frac{z^{2n+1}}{2n+1} + \cdots, \qquad z\in \mathbb{C}, \left|z\right|<1
		\end{equation*}
		The radius of convergence is $1$ for both series.
	\end{itemize}
\end{example}

\begin{notation}{$[z^n]$}{zn}
	Denote $[z^n]$ to be any function which is analytic and has a zero of order at least $n$ at $z=0$. For any analytic function at the origin, we can say
	\begin{equation}
		f(z) = a_0 + a_1 z + a_2 z^2 + \cdots + a_n z^n + [z^{n+1}],
	\end{equation}
	Where the coefficients are uniquely determined by the Taylor series.
\end{notation}

Therefore, finding the Taylor series coefficients of $f(z)$ is equivalent to finding the polynomial $P_n$ that $f(z) - P_n(z) = [z^{n+1}]$ has a zero of order at least $n+1$ at $z=0$. We can say that no matter the degree of $P_n$ is larger than $n$, the coefficients of $P_n$ up to $z^n$ are uniquely determined.
\begin{proof}
	Assume there are two such polynomials $P_n$ and $Q_n$, then $P_n(z)-Q_n(z) = [z^{n+1}]$. Assume that $P_n(z)-Q_n(z) = a_k z^k + a_{k+1} z^{k+1} + \cdots + a_m z^m$ with $a_k \neq 0$ and $k\leq n$, then $P_n(z)-Q_n(z)$ has a zero of order $k\leq n$ at $z=0$, which is a contradiction.
\end{proof}

Therefore, we cay easily say that if
\begin{equation*}
	f(z) = P_n(z) + [z^{n+1}], \qquad g(z) = Q_n(z) + [z^{n+1}],
\end{equation*}
\begin{equation*}
	f(z)g(z) = P_n(z)Q_n(z) + [z^{n+1}],
\end{equation*}
So as to determine the Taylor series of $fg$ at $z=0$ up to $z^n$, we only need to determine the product of the polynomials $P_n$ and $Q_n$ up to $z^n$. Explicitly, we have:

\begin{proposition}{Taylor Series of Operation of Functions}{Taylor Series of Operation of Functions}
	Let $f$ and $g$ be analytic in the region $\Omega$ and $z_0\in \Omega$. The Taylor series of $f$ and $g$ at $z_0$ are
	\begin{equation*}
		f(z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D
	\end{equation*}
	\begin{equation*}
		g(z) = \sum_{k=0}^{\infty} \frac{g^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D
	\end{equation*}
	if $D$ is an open disk centered at $z_0$ contained in $\Omega$. Then $f(z)$ and $g(z)$ can be expressed as power series in $D$, which converge uniformly to $f(z)$ and $g(z)$ on every compact subset of $D$.

	Moreover,
	\begin{itemize}
		\item For any constant $c\in \mathbb{C}$, the Taylor series of $cf$ at $z_0$ is
			\begin{equation*}
				c f(z) = \sum_{k=0}^{\infty} c \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D.
			\end{equation*}
		\item The Taylor series of $f+g$ at $z_0$ is
			\begin{equation*}
				f(z) + g(z) = \sum_{k=0}^{\infty} \left( \frac{f^{(k)}(z_0)}{k!} + \frac{g^{(k)}(z_0)}{k!} \right) (z-z_0)^k, \qquad z\in D.
			\end{equation*}
		\item The Taylor series of $fg$ at $z_0$ is
			\begin{equation*}
				f(z) g(z) = \sum_{k=0}^{\infty} \left( \sum_{j=0}^k \frac{f^{(j)}(z_0)}{j!} \frac{g^{(k-j)}(z_0)}{(k-j)!} \right) (z-z_0)^k, \qquad z\in D.
			\end{equation*}
		\item If $g(z_0)\neq 0$, then the Taylor series of $f / g$ at $z_0$ can be determined by:

			First letting $R_n$ be such that $P_n = Q_n R_n + [z^{n+1}]$, then taking the coefficients of $R_n$ up to $z^n$ to be the coefficients of the Taylor series of $f / g$ at $z_0$ up to $z^n$. Explicitly, we have
			\begin{equation*}
				\frac{f(z)}{g(z)} = \sum_{k=0}^{\infty} r_k (z-z_0)^k, \qquad z\in D,
			\end{equation*}
	This is because $f-R_ng = [z^{n+1}]$. And as $g(z_0)\neq 0$, $f / g - R_n = [z^{n+1}]$.
	\item For the composite function $f(g(z))$, for simplicity let $z_0=0$ and $g(0)=0$, then set
		\begin{equation*}
			f(w) = P_n(w) + [w^{n+1}], \qquad g(z) = Q_n(z) + [z^{n+1}], \quad Q_n(0)=0,
		\end{equation*}
		Then we have
		\begin{equation*}
			f(g(z)) = P_n(Q_n(z) + [z^{n+1}]) + [z^{n+1}] = P_n(Q_n(z)) + [z^{n+1}].
		\end{equation*}
	\item For the inverse function $f^{-1}(z)$, let $z_0=0$ and $f(0)=0$, assume $f'(0)\neq 0$ so there is a local homeomorphism inverse function. Let $f(z) = P_n(z) + [z^{n+1}]$ and $f^{-1}(z) = Q_n(z) + [z^{n+1}]$ with $P_n(0)=Q_n(0)=0$, then we have
		\begin{equation*}
			z = f(f^{-1}(z)) = P_n(Q_n(z)) + [z^{n+1}].
		\end{equation*}
		The proof of exiestence and uniqueness of $Q_n$ is due to the Lagrange Inversion Theorem.
	\end{itemize}
\end{proposition}

\begin{theorem}{Lagrange Inversion Theorem}{Lagrange Inversion Theorem}
	Let $f$ be analytic in the region $\Omega$ and $z_0\in \Omega$. The Taylor series of $f$ at $z_0$ is
	\begin{equation*}
		f(z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(z_0)}{k!} (z-z_0)^k, \qquad z\in D
	\end{equation*}
	if $D$ is an open disk centered at $z_0$ contained in $\Omega$. Then $f(z)$ can be expressed as a power series in $D$, which converges uniformly to $f(z)$ on every compact subset of $D$.

	Moreover, if $f'(z_0)\neq 0$, then there exists a local inverse function $f^{-1}$ such that $f^{-1}(f(z))=z$ for all $z$ in a neighborhood of $z_0$. The Taylor series of $f^{-1}$ at $w_0=f(z_0)$ is
	\begin{equation*}
		f^{-1}(w) = z_0 + \sum_{n=1}^{\infty} \frac{(w-w_0)^n}{n!} \left[ \frac{\mathrm{d}^{n-1}}{\mathrm{d} z^{n-1}} \left( \frac{z-z_0}{f(z)-w_0} \right)^n \right]_{z=z_0}, \qquad w\in D',
	\end{equation*}
	where $D'$ is an open disk centered at $w_0$ contained in the range of the local inverse function.
	
\end{theorem}

\subsection{The Laurent Series}

A series of the form
\begin{equation*}
	b_0 + b_1 z^{-1} + b_2 z^{-2} + \cdots + b_n z^{-n} + \cdots
\end{equation*}
can be viewed as a power series in $1 / z$. So it will converge in a region of the form $\left|z\right|>R$ for some $R>0$ and diverge for $\left|z\right|<R$.

For a more general form is called a Laurent series:
\begin{definition}{Laurent Series}{Laurent Series}
	A Laurent series centered at $z_0$ is a series of the form
	\begin{equation}
		\sum_{n=-\infty}^{\infty} a_n (z-z_0)^n
	\end{equation}
	where $a_n \in \mathbb{C}$ for all $n\in \mathbb{Z}$.
\end{definition}
A Laurent series can be viewed as the sum of two series: a power series in $z-z_0$ and a power series in $1 / (z-z_0)$. It would converge iff both series converge. Suppose the power series converges for $\left|z-z_0\right|<R_2$ and the other converges for $\left|z-z_0\right|>R_1$, then the Laurent series converges in the annulus $R_1<\left|z-z_0\right|<R_2$. Note that if $R_1 \geq R_2$, then there is no convergence region.

Conversely, we can start with an analytic function whose analyticity domain contains an annulus $R_1 < \left|z - a\right| < R_2$, then we can represent it as a Laurent series in that annulus.

\begin{theorem}{Laurent's Theorem}{Laurents Theorem}
	Let $f$ be analytic in the annulus $R_1<\left|z-a\right|<R_2$. Then $f$ can be represented as a Laurent series
	\begin{equation*}
		f(z) = \sum_{n=-\infty}^{\infty} a_n (z-a)^n, \qquad R_1<\left|z-a\right|<R_2,
	\end{equation*}
	where
	\begin{equation*}
		a_n = \frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r } \frac{f(\zeta)}{(\zeta-a)^{n+1}} \mathrm{d} \zeta, \qquad R_1<r<R_2.
	\end{equation*}
	The series converges uniformly to $f$ on every compact subset of the annulus.
\end{theorem}
\begin{proof}
	We try to represent $f = f_1+f_2$, and DEFINE
	\begin{equation*}
		f_1(z) = \frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r } \frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta, \qquad \left|z-a\right|<r<R_2,
	\end{equation*}
	\begin{equation*}
		f_2(z) = -\frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r } \frac{f(\zeta)}{\zeta-z} \mathrm{d} \zeta, \qquad R_1<r<\left|z-a\right|.
	\end{equation*}
	Both integral is irrelevant to the choice of $r$ in the given range. By Cauchy's integral formula, we have $f(z)=f_1(z)+f_2(z)$ for $R_1<\left|z-a\right|<R_2$. (Adding the two integrals means integrate via two circles with opposite orientation, which $\sim 0$).

	Also, we can see that $f_1$ is an analytic function in $\left|z-a\right|<R_2$ and $f_2$ is an analytic function in $\left|z-a\right|>R_1$. So we can expand them as power series:
	\begin{equation*}
		f_1(z) = \sum_{n=0}^{\infty} A_n (z-a)^n, \qquad \left|z-a\right|<R_2, A_n = \frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r } \frac{f(\zeta)}{(\zeta-a)^{n+1}} \mathrm{d} \zeta,
	\end{equation*}
	For $f_2$ we consider the transformation $z = 1 / z' + a, \zeta = 1 / \zeta' + a$, then
	\begin{equation*}
		f_2(1/z' + a) = \frac{1}{2 \pi i}\int_{\left|\zeta'\right|=1/r} \frac{f(1/\zeta' + a)}{\zeta'-z'} \frac{z'}{\zeta'} \mathrm{d} \zeta' = \sum_{n=0}^{\infty} B_n (z')^n, \qquad \left|z'\right|<1/R_1,
	\end{equation*}
	where
	\begin{equation*}
		\begin{aligned}
			B_n &= \frac{1}{n!} \left[ \frac{\mathrm{d}^n}{\mathrm{d} (z')^n} \int_{\left|\zeta'\right|=1/r} \frac{f(1/\zeta' + a)}{\zeta'-z'} \frac{z'}{\zeta'} \mathrm{d} \zeta' \right]_{z'=0} \\
			    &= \frac{1}{2 \pi i} \int_{\left|\zeta'\right|=1/r} \frac{f(1/\zeta' + a)}{(\zeta')^{n+1}} \mathrm{d} \zeta' \\
			    &= \frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r} f(\zeta) (\zeta-a)^{n-1} \mathrm{d} \zeta.
		\end{aligned}
	\end{equation*}
	\begin{equation*}
		f_2(z) = \sum_{n=0}^{\infty} B_n (1/(z-a))^n = \sum_{n=-\infty}^{-1} B_{-n} (z-a)^n, \qquad \left|z-a\right|>R_1.
	\end{equation*}
	In all, we can write:
	\begin{equation*}
		f(z) = \sum_{n=-\infty}^{\infty} a_n (z-a)^n, \qquad R_1<\left|z-a\right|<R_2, \qquad a_n = \frac{1}{2 \pi i} \int_{\left|\zeta-a\right|=r } \frac{f(\zeta)}{(\zeta-a)^{n+1}} \mathrm{d} \zeta.
	\end{equation*}
\end{proof}

The situation can be easily extended to $R_1=0$.

\section{Partial Fractions and Factorization}

There are two ways to represent a rational function: partial fractions and factorization of both numerator and denominator. Both are based on the fundamental theorem of algebra. We shall do this in a more general setting, that is, meromorphic functions.

\subsection{Partial Fractions}
Assume $f$ is meromorphic in a region $\Omega$, for each pole $b _{\nu}$ there is a neighborhood that contains no other poles. So we can write the Laurent series of $f$ at $b_{\nu}$:
\begin{equation*}
	P_{\nu}(\frac{1}{z-b_{\nu}}) + \text{ positive power series of } (z-b_{\nu}),
\end{equation*}
where $P_{\nu}$ is a polynomial in $1/(z-b_{\nu})$ without constant term. There are also finite terms in $P_{\nu}$ because $b_{\nu}$ is a pole and $\lim_{z\to b_{\nu}} f(z)(z-b_{\nu})^m = c \neq \infty $ for some $m\in \mathbb{Z}_+$.

Then we can subtract all these principal parts from $f$:
\begin{equation}
	f(z) = \sum_{\nu} P_{\nu}(\frac{1}{z-b_{\nu}}) + g(z).
\end{equation}
For there are at most countable poles in $\Omega$, the sum is well-defined. However, there are generally infinite poles and the sum may not converge. So we need to introduce some convergence factors to make the sum convergent. There is no harm done if we substract some analytic functions from $P_{\nu}$, as long as we add them to $g(z)$.

\begin{theorem}{Mittag-Leffler Theorem}{Mittag-Leffler Theorem}
	Let $\left\{ b _{\nu} \right\}$ be a sequence of complex numbers with $\lim_{\nu \to \infty } b _{\nu} = \infty $, and $P_{\nu}$ be polynomials without constant term. Then there exists meromorphic function $f$ in $\mathbb{C}$ whose poles are exactly at $b_{\nu}$ and the principal part of the Laurent series of $f$ at $b_{\nu}$ is $P_{\nu}(1/(z-b_{\nu}))$. And all such functions can be expressed in the following way:
	\begin{equation}
		f(z) = \sum_{\nu=1}^{\infty} \left[ P_{\nu}(\frac{1}{z-b_{\nu}}) - p_{\nu}(z) \right] + g(z),
	\end{equation}
	where $p_{\nu}(z)$ are polynomials chosen such that the series absolutely converges, and $g(z)$ is an entire function (analytic in $\mathbb{C}$).
\end{theorem}
\begin{proof}
	Suppose $b_{\nu} \neq 0$ for all $\nu$, otherwise we can just perform a slight translation. The function $P_{\nu}(1/(z-b_{\nu}))$ is analytic in $\left|z\right|<\left|b_{\nu}\right|$. So we can expand it as a Taylor series at $z=0$. Choose $p_{\nu}(z)$ to be a partial sum of the Taylor series at $z=0$, ending at the degree $n_{\nu}$.

	From the proof of theorem \ref{thm:All Derivatives Zero}, we know that if the maximum of $\left|P_{\nu}\right|$ for $\left|z\right|\leq \left|b _{\nu}\right| / 2$ is $M_{\nu}$, then
	\begin{equation*}
		\left|P_{\nu}(\frac{1}{z-b_{\nu}}) - p_{\nu}(z)\right| \leq 2 M_{\nu} \left( \frac{2 \left|z\right|}{\left|b_{\nu}\right|} \right)^{n_{\nu}+1}, \qquad \left|z\right|\leq \frac{\left|b_{\nu}\right|}{4}.
	\end{equation*}
	We choose $n_{\nu}$ such that
	\begin{equation*}
		2^{n_{\nu}} \geq M_{\nu} 2^{\nu}
	\end{equation*}
	For any $R$, there are only finite $\nu$ such that $\left|b_{\nu}\right|\leq 4R$. For sufficiently large $\nu$, that all $\left|b_{\nu}\right|>4R$, we have
	\begin{equation*}
		\left|P_{\nu}(\frac{1}{z-b_{\nu}}) - p_{\nu}(z)\right| \leq 2 M_{\nu} \left( \frac{2R}{\left|b_{\nu}\right|} \right)^{n_{\nu}+1} \leq 2M_{\nu} \left( \frac{1}{2} \right)^{n_{\nu}+1} \leq 2^{-\nu}.
	\end{equation*}
	So if we omit the first finite terms, the series converges uniformly and absolutely on $\left|z\right|\leq R$. As $R$ is arbitrary, the series converges uniformly and absolutely on every compact subset of $\mathbb{C}$. So the sum is meromorphic in $\mathbb{C}$ with poles exactly at $b_{\nu}$ and the principal part of the Laurent series of $f$ at $b_{\nu}$ is $P_{\nu}(1/(z-b_{\nu}))$.
\end{proof}

\begin{remark}
	Conversely, we can say that given a meromorphic function $f$ in $\mathbb{C}$ with poles at $b_{\nu}$, and the principal part of the Laurent series of $f$ at $b_{\nu}$ is $P_{\nu}(1/(z-b_{\nu}))$. Then we can find a suitable $g$ that has the same poles and principal parts, so $f-g$ is entire. If we merge the $f-g$ into the $g$ in the theorem, then we have the same form as in the theorem expressing $f$.

	For a slight clarification, if $f$ is meromorphic in $\mathbb{C}$ with infinitely many poles, then the poles must have a limit point at $\infty$. This is because any closed subset of $\mathbb{C}$ is compact, so there are only finite poles in that.
\end{remark}

\begin{example}{The Mittag-Leffler Theorem}{The Mittag-Leffler Theorem}
	\begin{itemize}
		\item Consider the function $\displaystyle \frac{\pi^2}{\sin ^2 \pi z}$. It has poles at all integers, and the principal part of the Laurent series at $n\in \mathbb{Z}$ is $\displaystyle \frac{1}{(z-n)^2}$. So we can express it as
			\begin{equation*}
				\frac{\pi^2}{\sin^2 \pi z} = \sum_{n=-\infty}^{\infty} \frac{1}{(z-n)^2} + g(z),
			\end{equation*}
		where $g(z)$ is an entire function. We prove that $g(z) = 0$. First notice that both sides have period $1$, so does $g(z)$. Also if we let $z = x + iy$ then
		\begin{equation*}
			|\sin \pi z|^2 = \cosh^2 \pi y - \cos^2 \pi x
		\end{equation*}
		which means that $\pi^2 / \sin^2 \pi z$ tends uniformly to $0$ as $y\to \pm \infty$. And the series also tends uniformly to $0$ as $y\to \pm \infty$. So $g(z)$ tends to $0$ uniformly as $y\to \pm \infty$. As $g(z)$ is periodic, it is bounded in $\mathbb{C}$. By Liouville's theorem, $g(z)$ is a constant. So $g(z)=0$.

		So we can infer that $g$ is bounded in $0\leq x\leq 1$ and from periodicity, it is bounded in $\mathbb{C}$. By Liouville's theorem, $g$ is a constant. As $g(iy)\to 0$ as $y\to \pm \infty$, we have $g(z)=0$. Therefore,
			\begin{equation*}
				\frac{\pi^2}{\sin^2 \pi z} = \sum_{n=-\infty}^{\infty} \frac{1}{(z-n)^2}.
			\end{equation*}
		\item Consider taking the integral of both sides, and the integral of the left side is $-\pi \cot \pi z$. The integral of the right side is inner compact uniform convergent in every domain that does not contain any integer. However, the series of $1 / (z-n)$ does not converge. So we need to introduce some convergence factors. We can take
			\begin{equation*}
				\sum_{n \neq 0} \left( \frac{1}{z-n} + \frac{1}{n} \right) + \frac{1}{z} = \sum_{n \neq 0} \frac{z}{n(z-n)} + \frac{1}{z}.
			\end{equation*}
			Indeed, this is just given by termwise integration from 0. So we have
			\begin{equation*}
				\pi \cot \pi z = \frac{1}{z} + \sum_{n \neq 0} \frac{z}{n(z-n)} + C = \frac{1}{z} + \sum_{n=1}^{\infty} \frac{2z}{z^2-n^2} + C.
			\end{equation*}
			For both sides are odd functions, $C=0$. Therefore,
			\begin{equation*}
				\pi \cot \pi z = \frac{1}{z} + \sum_{n=1}^{\infty} \frac{2z}{z^2-n^2}.
			\end{equation*}
		\item Conversely, we now study the sum
			\begin{equation*}
				\lim_{m \to \infty } \sum_{n=-m}^{m} \frac{(-1)^n}{z-n} = \frac{1}{z} + \sum_{n=1}^{\infty} (-1)^n \left( \frac{1}{z-n} + \frac{1}{z+n} \right) = \frac{1}{z} + \sum_{n=1}^{\infty} (-1)^n \frac{2z}{z^2-n^2}.
			\end{equation*}
			Which obviously is a meromorphic function with poles at all integers. Separate the odd and even terms, we have
			\begin{equation*}
				\sum_{n=-(2k+1)}^{2k+1} \frac{(-1)^n}{z-n} = \sum_{n=-k}^{k} \frac{1}{z-2n} - \sum_{n=-k-1}^{k} \frac{1}{z-(2n+1)}.
			\end{equation*}
			which has limit
			\begin{equation*}
				\frac{\pi}{2} \cot \frac{\pi z}{2} - \frac{\pi}{2} \cot \frac{\pi (z-1)}{2} = \frac{\pi}{\sin \pi z}.
			\end{equation*}
			So we have
			\begin{equation}
				\frac{\pi}{\sin \pi z} = \frac{1}{z} + \sum_{n=1}^{\infty} (-1)^n \frac{2z}{z^2-n^2} = \lim_{m \to \infty } \sum_{n=-m}^{m} \frac{(-1)^n}{z-n}.
			\end{equation}
	\end{itemize}
\end{example}

\subsection{Infinite Products}
An infinite product is an expression of the form
\begin{equation}
	\prod_{n=1}^{\infty} (1 + a_n), \qquad a_n \in \mathbb{C}, a_n \neq -1.
\end{equation}
whose limit definition is given by
\begin{equation*}
	\lim_{N \to \infty } \prod_{n=1}^N (1 + a_n).
\end{equation*}

Taking the logarithm, we have
\begin{equation*}
	\sum_{n=1}^{\infty} \log (1 + a_n).
\end{equation*}
where the branch of the logarithm is chosen to be the principal branch. Denote
\begin{equation*}
	P_n = \prod_{k=1}^n (1 + a_k), \qquad S_n = \sum_{k=1}^n \log (1 + a_k).
\end{equation*}
Then we have $P_n = e^{S_n}$. If $S_n \rightarrow S$, then $P_n \rightarrow e^S$. So the infinite product converges to $e^S$. Conversely, if $P_n \rightarrow P$, then it is not necessary that $S_n \rightarrow \log P$ in the principle branch. But we shall prove that if $P \neq 0$, then there exists an integer $m$ such that $S_n \rightarrow \log P + 2m \pi i$.
\begin{proof}
	SORRY
\end{proof}

\begin{theorem}{Infinite Products}{Infinite Products}
	The infinite product $\prod_{n=1}^{\infty} (1 + a_n)$ converges to a nonzero limit iff the series $\sum_{n=1}^{\infty} \log (1 + a_n)$ converges to a limit (the logarithm is taken in the principal branch).
\end{theorem}

Furthermore, as
\begin{equation*}
	\lim_{z \to 0} \frac{\log (1 + z)}{z} = 1,
\end{equation*}

We say that the infinite product converges absolutely if $\sum_{n=1}^{\infty} \log (1 + a_n)$ converges absolutely. And we have the following theorem:

\begin{theorem}{Absolute Convergence of Infinite Products}{Absolute Convergence of Infinite Products}
	The infinite product $\prod_{n=1}^{\infty} (1 + a_n)$ converges absolutely iff the series $\sum_{n=1}^{\infty} |a_n|$ converges.
\end{theorem}

It is quite clear to understand the uniform convergence of infinite products of functions.
\begin{definition}{Uniform Convergence of Infinite Products}{Uniform Convergence of Infinite Products}
	An infinite product of functions
	\begin{equation*}
		\prod_{n=1}^{\infty} \left( 1 + f_n(z) \right)
	\end{equation*}
	converges uniformly in a set $E$ if the sequence of partial products
	\begin{equation*}
		P_N(z) = \prod_{n=1}^N \left( 1 + f_n(z) \right)
	\end{equation*}
	converges uniformly in $E$ as $N \to \infty $.
\end{definition}

We can also verify uniform convergence via logarithms.

\begin{proposition}{Uniform Convergence by logarithm}{Uniform Convergence by logarithm}
	The infinite product of functions
	\begin{equation*}
		\prod_{n=1}^{\infty} \left( 1 + f_n(z) \right)
	\end{equation*}
	with $1+f_n(z) \neq 0$ for all $n$ and $z\in E$, converges uniformly in $E$ iff the series
	\begin{equation*}
		\sum_{n=1}^{\infty} \log \left(1 + f_n(z) \right)
	\end{equation*}
	converges uniformly in $E$ (the logarithm is taken in the principal branch).
\end{proposition}
\begin{proof}
	SORRY
\end{proof}

\begin{theorem}{Uniform Convergence by Series}{Uniform Convergence by Series}
	A sufficient and necessary condition for the infinite product of functions
	\begin{equation*}
		\prod_{n=1}^{\infty} \left( 1 + f_n(z) \right)
	\end{equation*}
	with $1+f_n(z) \neq 0$ for all $n$ and $z\in E$, to converge absolutely and  uniformly in $E$ is that the series
	\begin{equation*}
		\sum_{n=1}^{\infty} |f_n(z)|
	\end{equation*}
	converges uniformly in $E$.
\end{theorem}

\begin{remark}
	Here we see that the presence of zeros in the factors do give some difficulties. But we can restrict our attention to sets that only allow finite number of factors to be zero. If we omit these factors, then the remaining product is what we discussed above. Therefore, we are saying that the above theorems still hold in this case.
\end{remark}

\begin{proposition}{Compact Convergence Validity}{Compact Convergence Validity}
	If the infinite sequence of analytic functions
	\begin{equation*}
		f_1(z), f_2(z), \ldots
	\end{equation*}
	converges uniformly on every compact subset of a region $\Omega$, then it defines an analytic function in $\Omega$.
\end{proposition}

\subsection{Canonical Products}

We have developed the series representation of meromorphic functions. Now we turn to the product representation. We start with entire functions.

\begin{definition}{Entire Functions}{Entire Functions}
	A function $f$ is entire if it is analytic in $\mathbb{C}$.
\end{definition}

If $g$ is an entire function so is $f = e^g$ and $\forall z, f(z)\neq 0$. Conversely, if $f$ is entire and $\forall z, f(z)\neq 0$, then we can say that there exists an entire function $g$ such that $f = e^g$.
\begin{proof}
	Consider $f' / f$, which is analytic in $\mathbb{C}$. So there exists an entire function $g$ such that $g' = f' / f$. We have $f(z) e^{-g(z)}$ has zero derivative, so $f(z) = e^{g(z)+C}$.
\end{proof}

We can generalize this method to construct entire functions with a finite number of zeros. Assume $f$ has $m$-order zero for $0$, and all other zeros being $a_1, \ldots ,a_N$, counting multiplicities. Then we can write
\begin{equation}
	f(z) = z^m e^{g(z)} \prod_{n=1}^N \left( 1 - \frac{z}{a_n} \right),
\end{equation}
simply because
\begin{equation*}
	\frac{f(z)}{z^m \prod_{n=1}^N \left( z - a_n \right)}
\end{equation*}
has no zeros and entire.

As there are at most countable zeros for an entire function, we can try to generalize this to infinite zeros. We are tempted to write
\begin{equation*}
	f(z) = z^m e^{g(z)} \prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right),
\end{equation*}

If the product converges uniformly on every compact subset of $\mathbb{C}$, it defines an analytic function in $\mathbb{C}$. Also, as each factor has zeros exactly at $a_n$, the product has zeros exactly at $a_n$. Them this form is valid. However, the product converges absolutely iff $\sum_{n=1}^{\infty} |1 / a_n|$ converges, and when this happens, it also converges uniformly on every closed disk $|z| \leq R$. But in many cases, the zeros do not satisfy this condition.

This is quite similar to the situation of Mittag-Leffler theorem, where we need to introduce some convergence factors to make the product convergent. We can do this by proving the existence of polynomials $p_n(z)$ such that
\begin{equation}
	\prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right) e^{p_n(z)}
\end{equation}
converges to an entire function. 

\begin{theorem}{Weierstrass Factorization Theorem}{Weierstrass Factorization Theorem}
	Let $\left\{ a_n \right\}$ be a sequence of complex numbers with $\lim_{n \to \infty } |a_n| = \infty $. Then there exists an entire function $f$ whose zeros are exactly at $a_n$, counting multiplicities. And all such functions can be expressed in the following way:
	\begin{equation}
		f(z) = z^m e^{g(z)} \prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right) e^{p_n(z)},
	\end{equation}
	where $m$ is the order of zero at $0$, $g(z)$ is an entire function, and $p_n(z)$ are polynomials chosen such that the product converges uniformly on every compact subset of $\mathbb{C}$. Here we can choose
	\begin{equation}
		p_n(z) = \sum_{k=1}^{m_n} \frac{1}{k} \left( \frac{z}{a_n} \right)^k,
	\end{equation}
	for a suitable sequence of non-negative integers $m_n$. Specifically, we can take $m_n=n$.
\end{theorem}
\begin{proof}
	Consider that the product converges with the series with general term
	\begin{equation*}
		r_n = \log \left(1 - \frac{z}{a_n} \right) + p_n(z).
	\end{equation*}
	where the branch of the logarithm is chosen so that $\im r_n \in (-\pi, \pi]$. 

	Take $R>0$, we consider the $|a_n| > R$ part. In the disk $|z| \leq R$, the principal branch of $\log (1 - z/a_n)$ can be expanded as
	\begin{equation*}
		\log \left(1 - \frac{z}{a_n} \right) = -\sum_{k=1}^{\infty} \frac{1}{k} \left( \frac{z}{a_n} \right)^k.
	\end{equation*}
	We choose $p_n(z)$ to be the partial sum of the above series, by
	\begin{equation}
		p_n(z) = \sum_{k=1}^{m_n} \frac{1}{k} \left( \frac{z}{a_n} \right)^k.
	\end{equation}
	\begin{equation*}
		r_n = -\sum_{k=m_n+1}^{\infty} \frac{1}{k} \left( \frac{z}{a_n} \right)^k, \qquad |r_n| \leq \frac{1}{m_n+1} \left( \frac{R}{|a_n|} \right)^{m_n+1} \frac{1}{1 - R/|a_n|}.
	\end{equation*}
	We shall take $m_n$ that the series
	\begin{equation}
		\sum_{n=1}^{\infty} \frac{1}{m_n+1} \left( \frac{R}{|a_n|} \right)^{m_n+1}
	\end{equation}
	converges. If this happens, then we have $|r_n| \rightarrow 0$ as $n \to \infty $. So for sufficiently large $n$, $r_n$ has imaginary part in $(-\pi, \pi)$ as required. Also, this estimation implies uniform and absolute convergence of $\sum r_n$ in $|z| \leq R$. So for large $n$, the product is an analytic function in $|z| \leq R$. Add the finite number of terms omitted, the product is still analytic.

	Now, if we take $m_n=n$, then the series converges for any $R>0$ because $\lim_{n \to \infty } |a_n| = \infty $. So the product converges uniformly on every compact subset of $\mathbb{C}$, defining an entire function.
\end{proof}

\begin{corollary}{Structure if Meromorphic Functions}{Structure if Meromorphic Functions}
	Every meromorphic function in $\mathbb{C}$ can be expressed as the quotient of two entire functions.
\end{corollary}
\begin{proof}
	Let $F$ be a meromorphic function in $\mathbb{C}$, then take an entire function $g$ whose zeros are exactly at the poles of $F$, counting multiplicities. (poles are countable tending to $\infty$, by the compactness of closed disks). Then $f = Fg$ is entire.
\end{proof}

The representation of theorem \ref{thm:Weierstrass Factorization Theorem} is interesting when we can take all $m_n=h$ to be the same. From the proof we know that this is possible if
\begin{equation}
	\sum_{n=1}^{\infty} \frac{1}{h+1} \left( \frac{R}{|a_n|} \right)^{h+1} < \infty , \forall R \quad \Rightarrow \quad \sum_{n=1}^{\infty} \frac{1}{|a_n|^{h+1}} < \infty .
\end{equation}

\begin{definition}{Canonical Product}{Canonical Product}
	Define $h$ to be the smallest non-negative integer such that
	\begin{equation*}
		\sum_{n=1}^{\infty} \frac{1}{|a_n|^{h+1}} < \infty .
	\end{equation*}
	Then $h$ is called the genus of the sequence $\left\{ a_n \right\}$. The expression
	\begin{equation}
		\prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right) \exp \left[ \left( \frac{z}{a_n} \right) + \frac{1}{2} \left( \frac{z}{a_n} \right)^2 + \cdots + \frac{1}{h} \left( \frac{z}{a_n} \right)^h \right]
	\end{equation}
	is called the canonical product of genus $h$ associated with the sequence $\left\{ a_n \right\}$.
\end{definition}

If we use the canonical product, then the Weierstrass factorization theorem can be uniquely expressed as
\begin{equation*}
	f(z) = z^m e^{g(z)} \prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right) \exp \left[ \left( \frac{z}{a_n} \right) + \frac{1}{2} \left( \frac{z}{a_n} \right)^2 + \cdots + \frac{1}{h} \left( \frac{z}{a_n} \right)^h \right],
\end{equation*}
If $g$ reduces to a polynomial, then we say that $f$ is of finite genus. The genus of $f$ is defined to be $\max \{ \deg g, h \}$.

\begin{remark}
	The genus of an entire function gives a measure of the growth of the function as $|z| \to \infty $. We shall study this in detail later.
\end{remark}

As an example, consider that
\begin{equation*}
	\sin \pi z = z e^{g(z)} \prod_{n\neq 0} \left( 1 - \frac{z}{n} \right) e^{z/n}.
\end{equation*}
Here we take $h=1$ as $\sum 1/n^2$ converges and $\sum 1/n$ diverges. To find $g(z)$, we take logarithm and differentiate both sides: (Due to uniform convergence on every compact subset that does not contain any integer).
\begin{equation*}
	\pi \cot \pi z = \frac{1}{z} + g'(z) + \sum_{n\neq 0} \left( \frac{1}{z-n} + \frac{1}{n} \right).
\end{equation*}
From previous example, we know that $g'(z) = 0$. Also, as $\sin \pi z / z \rightarrow \pi$ as $z \to 0$, we have $e^{g(z)} = \pi$, so
\begin{equation}
	\sin \pi z = \pi z \prod_{n\neq 0} \left( 1 - \frac{z}{n} \right) e^{z/n} = \pi z \prod_{n=1}^{\infty} \left( 1 - \frac{z^2}{n^2} \right).
\end{equation}
The last equality is due to pairing the $n$ and $-n$ terms. So $\sin $ is of genus 1.

\begin{theorem}{The Interpolation Theorem}{The Interpolation Theorem}
	Let $\left\{ a_n \right\}$ be a sequence of different complex numbers with $\lim_{n \to \infty } |a_n| = \infty $, and let $\left\{ A_n \right\}$ be a sequence of complex numbers. Then there exists an entire function $f$ such that
	\begin{equation*}
		f(a_n) = A_n, \qquad \forall n.
	\end{equation*}
\end{theorem}
\begin{proof}
	Let $g(z)$ be an entire function whose zeros are exactly at $a_n$, all simple zeros (by Weierstrass factorization theorem). Then consider
	\begin{equation*}
		f(z) = \sum_{n=1}^{\infty} A_n \frac{g(z)}{g'(a_n)(z-a_n)} e^{\gamma_n(z-a_n)},
	\end{equation*}

	SORRY, to be continued
\end{proof}

\subsection{The Gamma Function}
The Sine function example shows a way to define functions via their zeros. It has both side zeros. The simplest function for negative side zeros is the canonical product
\begin{equation}
	G(z) = \prod_{n=1}^{\infty} \left( 1 + \frac{z}{n} \right) e^{-z/n}.
\end{equation}
where easily
\begin{equation}
	zG(z)G(-z) = \frac{\sin \pi z}{\pi}.
\end{equation}
We also notice that $G(z-1)$ has simple poles at negative integers and $0$. So is $zG(z)$. So we can write
\begin{equation}
	G(z-1) = z e^{ \gamma(z)} G(z),
\end{equation}
where $ \gamma$ is entire. By taking logarithm and differentiating both sides, we have
\begin{equation*}
	\sum_{n=1}^{\infty} \left( \frac{1}{n+z-1} - \frac{1}{n} \right) = \frac{1}{z} + \gamma'(z) + \sum_{n=1}^{\infty} \left( \frac{1}{n+z} - \frac{1}{n} \right).
\end{equation*}
Subtracting both sides, we have $\gamma'(z) = 0$. So $\gamma(z) = \gamma$ is a constant. Evaluating at $z=1$, we have
\begin{equation*}
	G(0) = e^{\gamma} G(1) \Rightarrow e^{-\gamma} = \prod_{n=1}^{\infty} \left( 1 + \frac{1}{n} \right) e^{-1/n}
\end{equation*}
The right side restates as
\begin{equation*}
	\prod_{n=1}^{N} \frac{n+1}{n} e^{-1/n} = (N+1) e^{-\sum_{n=1}^N 1/n} 
\end{equation*}
Thus we have
\begin{equation}
	\gamma = \lim_{n \to \infty } \left( \sum_{k=1}^n \frac{1}{k} - \log n \right),
\end{equation}
called the Euler-Mascheroni constant, with approximate value $0.5772 \ldots $.

Take $H(z) = G(z) e^{\gamma z}$, then we have $H(z-1) = z H(z)$, then $ \Gamma(z) = 1 / (zH(z))$ satisfies
\begin{equation*}
	\Gamma(z+1) = z \Gamma(z).
\end{equation*}
Our definition leads to the explicit formula
\begin{equation}
	\Gamma(z) = \frac{e^{-\gamma z}}{z} \prod_{n=1}^{\infty} \left( 1 + \frac{z}{n} \right)^{-1} e^{z/n}.
\end{equation}
And
\begin{equation}
	\Gamma(z) \Gamma(1-z) = \frac{\pi}{\sin \pi z}.
\end{equation}
It has poles at $0, -1, -2, \ldots $ all simple poles, without zeros. Also, we have $ \Gamma(1) = 1$, so by induction, $\Gamma(n) = (n-1)!$ for $n\in \mathbb{Z}_+$. Also from the functional equation, we have $ \Gamma(1/2) = \sqrt{\pi}$.

%--------- TO BE CONTINUED --------------

\section{Entire Functions}
In this part we study the growth of entire functions related to their zeros and their genus.

\subsection{Jensen's Formula}

If $f$ is analytic, then $\log |f(z)|$ is a harmonic function except at the zeros of $f$. So if $f$ is analytic in a disk $|z|\leq \rho$ and has no zeros in the disk, then by the mean value property of harmonic functions, we have
\begin{equation*}
	\log |f(0)| = \frac{1}{2\pi} \int_0^{2\pi} \log |f(\rho e^{i\theta})| \mathrm{d} \theta.
\end{equation*}

The equation still holds if $f$ has zeros on the boundary $|z|=\rho$. For each zero $ \rho e^{i\theta_i}$ on the boundary (only finite many), we can factor it out as
\begin{equation*}
	g(z) = \frac{f(z)}{\prod (z - \rho e^{i\theta_i})},
\end{equation*}
So we have
\begin{equation*}
	\log \left| \frac{f(0)}{\prod (- \rho e^{i\theta_i})} \right| = \frac{1}{2\pi} \int_0^{2\pi} \log \left| \frac{f(\rho e^{i\theta})}{\prod (\rho e^{i\theta} - \rho e^{i\theta_i})} \right| \mathrm{d} \theta.
\end{equation*}
It is sufficient to prove that
\begin{equation*}
	\log \rho = \frac{1}{2\pi} \int_0^{2\pi} \log |\rho e^{i\theta} - \rho e^{i\theta_i}| \mathrm{d} \theta \Leftrightarrow \frac{1}{2\pi} \int_0^{2\pi} \log |e^{i\theta} - 1| \mathrm{d} \theta = 0.
\end{equation*}
which is obvious by $\displaystyle \int_0^{\pi} \log \sin \theta \mathrm{d} \theta = -\pi \log 2$.
Adding the equations for all zeros on the boundary, we have the desired result.

\begin{remark}
	Here the integral can be understood as an improper integral if there are zeros on the boundary.
\end{remark}

Now we consider the case that $f$ has zeros in the disk. Let the zeros of $f$ in $|z|<\rho$ be $a_1, a_2, \ldots , a_n$, counting multiplicities. Assume that none of them is $0$. We can factor them out as
\begin{equation}
	F(z) = f(z) \prod_{i=1}^n \frac{\rho^2 - \overline{a_i} z}{\rho (z - a_i)}.
\end{equation}
Notice the right side is a linear fractional transformation that maps the disk onto itself, so $|F(z)| = |f(z)|$ on $|z|=\rho$. Also, $F$ has no zeros in $|z|<\rho$. So by the previous result, we have
\begin{equation*}
	\log |F(0)| = \frac{1}{2\pi} \int_0^{2\pi} \log |F(\rho e^{i\theta})| \mathrm{d} \theta = \frac{1}{2\pi} \int_0^{2\pi} \log |f(\rho e^{i\theta})| \mathrm{d} \theta.
\end{equation*}

Substituting back, we have the Jensen's formula:
\begin{theorem}{Jensen's Formula}{Jensen's Formula}
	Let $f$ be analytic in $|z| \leq \rho$ with zeros $a_1, a_2, \ldots , a_n$ in $|z|<\rho$, counting multiplicities. Then if $f(0) \neq 0$, we have
	\begin{equation}
		\log |f(0)| = \sum_{i=1}^n \log \frac{|a_i|}{\rho} + \frac{1}{2\pi} \int_0^{2\pi} \log |f(\rho e^{i\theta})| \mathrm{d} \theta.
	\end{equation}
\end{theorem}
If $f(0) = 0$ with order $h$, we can factor out the zero at $0$ by
\begin{equation*}
	F_1(z) = F(z) \left(\frac{\rho}{z} \right)^h
\end{equation*}
and apply the previous result to $F_1(z)$, we have
\begin{equation}
	\log \left| F_1(0) \right| = \frac{1}{2\pi} \int_0^{2\pi} \log |f(\rho e^{i\theta})| \mathrm{d} \theta.
\end{equation}

We can also generalize Jensen's formula just as Poisson formula, if $f(z)\neq 0$, we obtain
\begin{equation}
	\log |f(z)| = -\sum_{i=1}^n \log \left| \frac{\rho^2 - \overline{a_i} z}{\rho (z - a_i)} \right| + \frac{1}{2\pi} \int_0^{2\pi} \re \left\{ \frac{\rho e^{i\theta} + z}{\rho e^{i\theta} - z} \right\} \log |f(\rho e^{i\theta})| \mathrm{d} \theta,
\end{equation}
called the Poisson-Jensen formula.

\subsection{Hadamard's Factorization Theorem}
Let $f$ be an entire function with zeros $a_1, a_2, \ldots $, and $f(0) \neq 0$. From the Weierstrass factorization theorem, we have
\begin{equation*}
	f(z) = e^{g(z)} \prod_{n=1}^{\infty} \left( 1 - \frac{z}{a_n} \right) e^{p_n(z)}, \qquad p_n(z) = \sum_{k=1}^{m_n} \frac{1}{k} \left( \frac{z}{a_n} \right)^k.
\end{equation*}

\begin{definition}{Order of Entire Function}{Order of Entire Function}
	Denote $M(r) = \max_{|z|=r} |f(z)|$. The order of $f$ is defined as
	\begin{equation*}
		\lambda = \limsup_{r \to \infty } \frac{\log \log M(r)}{\log r}.
	\end{equation*}
\end{definition}
Equivalently, $ \lambda$ is the smallest number that for every $\epsilon > 0$, we have
\begin{equation*}
	M(r) \leq \exp (r^{\lambda + \epsilon})
\end{equation*}
for sufficiently large $r$.

As we can see, both genus and order measure the growth of entire functions. We have the following important theorem relating them.
\begin{theorem}{Genus and Order}{Genus and Order}
	Let $f$ be an entire function. Then the genus $h$ and the order $\lambda$ of $f$ satisfy
	\begin{equation}
		h \leq \lambda \leq h + 1.
	\end{equation}
\end{theorem}
\begin{proof}
	Assume $f$ has genus $h$. Then $e^{g}$ has order $\leq h$. The convergence of the canonical product implies $\sum 1/|a_n|^{h+1}$ converges. Denote the canonical product by $P(z)$, and write
	\begin{equation*}
		E_h(u) = (1-u) \exp \left( u + \frac{u^2}{2} + \cdots + \frac{u^h}{h} \right). \quad E_0(u) = 1-u.
	\end{equation*}
	We shall prove that $\log |E_h(u)| \leq (2h+1) |u|^{h+1}$ for all $u$.

	If $|u|<1$ we have
	\begin{equation*}
		\log |E_h(u)| \leq \frac{|u|^{h+1}}{h+1} + \cdots \leq \frac{1}{h+1} \frac{|u|^{h+1}}{1 - |u|}
	\end{equation*}
\end{proof}

\end{document}
